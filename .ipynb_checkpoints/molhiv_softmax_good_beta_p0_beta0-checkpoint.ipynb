{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "OBxXkQOYvhNz",
    "outputId": "43f1acc3-0082-4f3e-d923-7788da74b19c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ogb in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (1.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (from ogb) (1.15.0)\n",
      "Requirement already satisfied: torch>=1.2.0 in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (from ogb) (1.6.0+cu101)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (from ogb) (1.19.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (from ogb) (1.1.0)\n",
      "Requirement already satisfied: tqdm>=4.29.0 in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (from ogb) (4.48.2)\n",
      "Requirement already satisfied: outdated>=0.2.0 in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (from ogb) (0.2.0)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (from ogb) (1.25.10)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (from ogb) (0.21.3)\n",
      "Requirement already satisfied: future in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (from torch>=1.2.0->ogb) (0.18.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (from pandas>=0.24.0->ogb) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (from pandas>=0.24.0->ogb) (2.8.1)\n",
      "Requirement already satisfied: requests in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (from outdated>=0.2.0->ogb) (2.24.0)\n",
      "Requirement already satisfied: littleutils in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (from outdated>=0.2.0->ogb) (0.2.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (from scikit-learn>=0.20.0->ogb) (1.5.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (from scikit-learn>=0.20.0->ogb) (0.16.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (from requests->outdated>=0.2.0->ogb) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (from requests->outdated>=0.2.0->ogb) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eric\\miniconda3\\envs\\my-rdkit-env-tf1\\lib\\site-packages (from requests->outdated>=0.2.0->ogb) (2020.6.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install ogb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6oAevLez2il"
   },
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_softmax, scatter_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "13A6KgTVui6Q"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Embedding, ModuleList\n",
    "from torch.nn import Sequential, Linear, BatchNorm1d, ReLU\n",
    "from torch_scatter import scatter, scatter_mean, scatter_add, scatter_sum\n",
    "from torch_geometric.nn import GINConv, GINEConv\n",
    "\n",
    "\n",
    "class AtomEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(AtomEncoder, self).__init__()\n",
    "\n",
    "        self.embeddings = torch.nn.ModuleList()\n",
    "\n",
    "        for i in range(9):\n",
    "            self.embeddings.append(Embedding(100, hidden_channels))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for embedding in self.embeddings:\n",
    "            embedding.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(1)\n",
    "\n",
    "        out = 0\n",
    "        for i in range(x.size(1)):\n",
    "            out += self.embeddings[i](x[:, i])\n",
    "        return out\n",
    "\n",
    "\n",
    "class BondEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(BondEncoder, self).__init__()\n",
    "\n",
    "        self.embeddings = torch.nn.ModuleList()\n",
    "\n",
    "        for i in range(3):\n",
    "            self.embeddings.append(Embedding(6, hidden_channels))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for embedding in self.embeddings:\n",
    "            embedding.reset_parameters()\n",
    "\n",
    "    def forward(self, edge_attr):\n",
    "        if edge_attr.dim() == 1:\n",
    "            edge_attr = edge_attr.unsqueeze(1)\n",
    "\n",
    "        out = 0\n",
    "        for i in range(edge_attr.size(1)):\n",
    "            out += self.embeddings[i](edge_attr[:, i])\n",
    "        return out\n",
    "\n",
    "\n",
    "class Global_Gen_Sum_Mean_Max_Pool(nn.Module):\n",
    "    def __init__(self, family = \"softmax\", p = 1.0, beta = 1.0, \n",
    "                 trainable_p = False, trainable_beta = False):\n",
    "        r\"\"\"Performs batch-wise graph-level-outputs by transforming node\n",
    "        features based on a Generalized Aggr-Mean-Max function, so that\n",
    "        for a single graph :math:`\\mathcal{G}_i` its output is computed\n",
    "        deppending on the family of transformations by:\n",
    "        .. math::\n",
    "            \\mathbf{r}_i = \\frac{1}{\\beta*N_i} \\sum_{n=1}^{N_i} \\mathbf{softmax} \\left( \\mathbf{x}_n * p \\right) * \\mathbf{x}_n\n",
    "        for softmax aggregation or\n",
    "        .. math::\n",
    "            \\mathbf{r}_i = \\left( \\frac{1}{\\beta*N_i} \\sum_{n=1}^{N_i} \\mathbf{x}_n^{p} \\right)^{1/p}\n",
    "        for power mean aggregation.\n",
    "\n",
    "        Args:\n",
    "            family (str): family of generalized mean-max functions to use. \n",
    "                Either \"softmax\" or \"power\" for eq. 1 or eq. 2 respectively.\n",
    "            p (float): parameter for the generalized mean-max function\n",
    "            trainable (bool): whether the value of p is learnable during training.\n",
    "        \"\"\"\n",
    "        super(Global_Gen_Sum_Mean_Max_Pool, self).__init__()\n",
    "        \n",
    "        self.family         = family\n",
    "        self.base_p         = p\n",
    "        self.base_beta      = beta\n",
    "        self.trainable_p    = trainable_p\n",
    "        self.trainable_beta = trainable_beta\n",
    "        # define params\n",
    "        self.p = torch.nn.Parameter(torch.tensor([p], device=device),\n",
    "                                    requires_grad=trainable_p)# .to(device)\n",
    "        self.beta = torch.nn.Parameter(torch.tensor([beta], device=device),\n",
    "                                       requires_grad=trainable_beta)# .to(device)\n",
    "\n",
    "    def forward(self, x, batch, bsize=None):\n",
    "        r\"\"\"Args:\n",
    "            x (Tensor): Node feature matrix\n",
    "                :math:`\\mathbf{X} \\in \\mathbb{R}^{(N_1 + \\ldots + N_B) \\times F}`.\n",
    "            batch (LongTensor): Batch vector :math:`\\mathbf{b} \\in {\\{ 0, \\ldots,\n",
    "                B-1\\}}^N`, which assigns each node to a specific example.\n",
    "            size (int, optional): Batch-size :math:`B`.\n",
    "                Automatically calculated if not given. (default: :obj:`None`)\n",
    "        :rtype: :class:`Tensor`\n",
    "        \"\"\"\n",
    "        bsize = int(batch.max().item() + 1) if bsize is None else bsize\n",
    "        n_nodes = scatter_sum(torch.ones_like(x), batch, dim=0, dim_size=bsize)\n",
    "        if self.family == \"softmax\":\n",
    "            out = scatter_softmax(self.p * x.detach(), batch, dim=0)\n",
    "            return scatter_add(x * out,\n",
    "                                batch, dim=0, dim_size=bsize)*n_nodes / (1+self.beta*(n_nodes-1))\n",
    "\n",
    "        elif self.family == \"power\":\n",
    "            #Â numerical stability - avoid powers of large numbers or negative ones\n",
    "            min_x, max_x = 1e-7, 1e+3\n",
    "            torch.clamp_(x, min_x, max_x)\n",
    "            out = scatter_add(torch.pow(x, self.p),\n",
    "                               batch, dim=0, dim_size=bsize) / (1+self.beta*(n_nodes-1))\n",
    "            torch.clamp_(out, min_x, max_x)\n",
    "            return torch.pow(out, 1 / self.p)\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.p and torch.is_tensor(self.p):\n",
    "            self.p.data.fill_(self.base_p)\n",
    "        if self.beta and torch.is_tensor(self.beta):\n",
    "            self.beta.data.fill_(self.base_beta)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Generalized Aggr-Mean-Max global pooling layer with params:\" + \\\n",
    "               str({\"family\": self.family,\n",
    "                    \"base_p\": self.base_p,\n",
    "                    \"base_beta\"     : self.base_beta,\n",
    "                    \"trainable_p\"   : self.trainable_p,\n",
    "                    \"trainable_beta\": self.trainable_beta})\n",
    "\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_layers, dropout=0.0,\n",
    "                 inter_message_passing=True):\n",
    "        super(Net, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.inter_message_passing = inter_message_passing\n",
    "\n",
    "        self.atom_encoder = AtomEncoder(hidden_channels)\n",
    "        self.clique_encoder = Embedding(4, hidden_channels)\n",
    "\n",
    "        self.bond_encoders = ModuleList()\n",
    "        self.atom_convs = ModuleList()\n",
    "        self.atom_batch_norms = ModuleList()\n",
    "        self.reader = Global_Gen_Sum_Mean_Max_Pool(family = \"softmax\", p = 1e-5, beta = 1e-5, \n",
    "                                                   trainable_p = True, trainable_beta = True)\n",
    "\n",
    "        for _ in range(num_layers):\n",
    "            self.bond_encoders.append(BondEncoder(hidden_channels))\n",
    "            nn = Sequential(\n",
    "                Linear(hidden_channels, 2 * hidden_channels),\n",
    "                BatchNorm1d(2 * hidden_channels),\n",
    "                ReLU(),\n",
    "                Linear(2 * hidden_channels, hidden_channels),\n",
    "            )\n",
    "            self.atom_convs.append(GINEConv(nn, train_eps=True))\n",
    "            self.atom_batch_norms.append(BatchNorm1d(hidden_channels))\n",
    "\n",
    "        self.clique_convs = ModuleList()\n",
    "        self.clique_batch_norms = ModuleList()\n",
    "\n",
    "        for _ in range(num_layers):\n",
    "            nn = Sequential(\n",
    "                Linear(hidden_channels, 2 * hidden_channels),\n",
    "                BatchNorm1d(2 * hidden_channels),\n",
    "                ReLU(),\n",
    "                Linear(2 * hidden_channels, hidden_channels),\n",
    "            )\n",
    "            self.clique_convs.append(GINConv(nn, train_eps=True))\n",
    "            self.clique_batch_norms.append(BatchNorm1d(hidden_channels))\n",
    "\n",
    "        self.atom2clique_lins = ModuleList()\n",
    "        self.clique2atom_lins = ModuleList()\n",
    "\n",
    "        for _ in range(num_layers):\n",
    "            self.atom2clique_lins.append(\n",
    "                Linear(hidden_channels, hidden_channels))\n",
    "            self.clique2atom_lins.append(\n",
    "                Linear(hidden_channels, hidden_channels))\n",
    "\n",
    "        self.atom_lin = Linear(hidden_channels, hidden_channels)\n",
    "        self.clique_lin = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.atom_encoder.reset_parameters()\n",
    "        self.clique_encoder.reset_parameters()\n",
    "\n",
    "        for emb, conv, batch_norm in zip(self.bond_encoders, self.atom_convs,\n",
    "                                         self.atom_batch_norms):\n",
    "            emb.reset_parameters()\n",
    "            conv.reset_parameters()\n",
    "            batch_norm.reset_parameters()\n",
    "\n",
    "        for conv, batch_norm in zip(self.clique_convs,\n",
    "                                    self.clique_batch_norms):\n",
    "            conv.reset_parameters()\n",
    "            batch_norm.reset_parameters()\n",
    "\n",
    "        for lin1, lin2 in zip(self.atom2clique_lins, self.clique2atom_lins):\n",
    "            lin1.reset_parameters()\n",
    "            lin2.reset_parameters()\n",
    "\n",
    "        self.atom_lin.reset_parameters()\n",
    "        self.clique_lin.reset_parameters()\n",
    "        self.lin.reset_parameters()\n",
    "        self.reader.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.atom_encoder(data.x.squeeze())\n",
    "\n",
    "        if self.inter_message_passing:\n",
    "            x_clique = self.clique_encoder(data.x_clique.squeeze())\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            edge_attr = self.bond_encoders[i](data.edge_attr)\n",
    "            x = self.atom_convs[i](x, data.edge_index, edge_attr)\n",
    "            x = self.atom_batch_norms[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "\n",
    "            if self.inter_message_passing:\n",
    "                row, col = data.atom2clique_index\n",
    "\n",
    "                x_clique = x_clique + F.relu(self.atom2clique_lins[i](scatter(\n",
    "                    x[row], col, dim=0, dim_size=x_clique.size(0),\n",
    "                    reduce='mean')))\n",
    "\n",
    "                x_clique = self.clique_convs[i](x_clique, data.tree_edge_index)\n",
    "                x_clique = self.clique_batch_norms[i](x_clique)\n",
    "                x_clique = F.relu(x_clique)\n",
    "                x_clique = F.dropout(x_clique, self.dropout,\n",
    "                                     training=self.training)\n",
    "\n",
    "                x = x + F.relu(self.clique2atom_lins[i](scatter(\n",
    "                    x_clique[col], row, dim=0, dim_size=x.size(0),\n",
    "                    reduce='mean')))\n",
    "\n",
    "        x = self.reader(x, data.batch)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.atom_lin(x)\n",
    "\n",
    "        if self.inter_message_passing:\n",
    "            tree_batch = torch.repeat_interleave(data.num_cliques)\n",
    "            x_clique = scatter(x_clique, tree_batch, dim=0, dim_size=x.size(0),\n",
    "                               reduce='mean')\n",
    "            x_clique = F.dropout(x_clique, self.dropout,\n",
    "                                 training=self.training)\n",
    "            x_clique = self.clique_lin(x_clique)\n",
    "            x = x + x_clique\n",
    "\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dkP00CdeukM5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import tree_decomposition\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdchem import BondType\n",
    "\n",
    "bonds = [BondType.SINGLE, BondType.DOUBLE, BondType.TRIPLE, BondType.AROMATIC]\n",
    "\n",
    "\n",
    "def mol_from_data(data):\n",
    "    mol = Chem.RWMol()\n",
    "\n",
    "    x = data.x if data.x.dim() == 1 else data.x[:, 0]\n",
    "    for z in x.tolist():\n",
    "        mol.AddAtom(Chem.Atom(z))\n",
    "\n",
    "    row, col = data.edge_index\n",
    "    mask = row < col\n",
    "    row, col = row[mask].tolist(), col[mask].tolist()\n",
    "\n",
    "    bond_type = data.edge_attr\n",
    "    bond_type = bond_type if bond_type.dim() == 1 else bond_type[:, 0]\n",
    "    bond_type = bond_type[mask].tolist()\n",
    "\n",
    "    for i, j, bond in zip(row, col, bond_type):\n",
    "        assert bond >= 1 and bond <= 4\n",
    "        mol.AddBond(i, j, bonds[bond - 1])\n",
    "\n",
    "    return mol.GetMol()\n",
    "\n",
    "\n",
    "class JunctionTreeData(Data):\n",
    "    def __inc__(self, key, item):\n",
    "        if key == 'tree_edge_index':\n",
    "            return self.x_clique.size(0)\n",
    "        elif key == 'atom2clique_index':\n",
    "            return torch.tensor([[self.x.size(0)], [self.x_clique.size(0)]])\n",
    "        else:\n",
    "            return super(JunctionTreeData, self).__inc__(key, item)\n",
    "\n",
    "\n",
    "class JunctionTree(object):\n",
    "    def __call__(self, data):\n",
    "        mol = mol_from_data(data)\n",
    "        out = tree_decomposition(mol, return_vocab=True)\n",
    "        tree_edge_index, atom2clique_index, num_cliques, x_clique = out\n",
    "\n",
    "        data = JunctionTreeData(**{k: v for k, v in data})\n",
    "\n",
    "        data.tree_edge_index = tree_edge_index\n",
    "        data.atom2clique_index = atom2clique_index\n",
    "        data.num_cliques = num_cliques\n",
    "        data.x_clique = x_clique\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r-BnRJKkukQ8"
   },
   "outputs": [],
   "source": [
    "# edit the function causing the error: add argument chem=None + modify function code: \n",
    "# Chem=chem if chem is not None else Chem\n",
    "\n",
    "# tree_decomposition(Chem.MolFromSmiles(\"cicccc1c\"), return_vocab=True)\n",
    "#Â once modified and saved, restart the environmnet, comment this cell and run the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "l-eGz7HtCLCr",
    "outputId": "a5812a61-fea7-4301-dd16-9d75ea62035b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from ogb.graphproppred import PygGraphPropPredDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.transforms import Compose\n",
    "\n",
    "class Argparse_emulate():\n",
    "    def __init__(self, device=0, hidden_channels=256, num_layers=2, dropout=0.5,\n",
    "               epochs=100, no_inter_message_passing=\"store_true\"):\n",
    "        self.device = device\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.epochs = epochs\n",
    "        self.no_inter_message_passing = no_inter_message_passing\n",
    "        return\n",
    "\n",
    "args = Argparse_emulate()\n",
    "# parser.add_argument('--device', type=int, default=0)\n",
    "# parser.add_argument('--hidden_channels', type=int, default=256)\n",
    "# parser.add_argument('--num_layers', type=int, default=2)\n",
    "# parser.add_argument('--dropout', type=float, default=0.5)\n",
    "# parser.add_argument('--epochs', type=int, default=100)\n",
    "# parser.add_argument('--no_inter_message_passing', action='store_true')\n",
    "# args = parser.parse_args()\n",
    "# print(args)\n",
    "\n",
    "\n",
    "class OGBTransform(object):\n",
    "    # OGB saves atom and bond types zero-index based. We need to revert that.\n",
    "    def __call__(self, data):\n",
    "        data.x[:, 0] += 1\n",
    "        data.edge_attr[:, 0] += 1\n",
    "        return data\n",
    "\n",
    "\n",
    "transform = Compose([OGBTransform(), JunctionTree()])\n",
    "\n",
    "name = 'ogbg-molhiv'\n",
    "dataset = PygGraphPropPredDataset(name, 'data', pre_transform=transform)\n",
    "\n",
    "# correct splits\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_dataset = dataset[split_idx['train']]\n",
    "val_dataset = dataset[split_idx['valid']]\n",
    "test_dataset = dataset[split_idx['test']]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, 128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, 128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, 128, shuffle=False)\n",
    "\n",
    "\n",
    "device = f'cuda:{args.device}' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, vals=False):\n",
    "    values = []\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for i,data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        mask = ~torch.isnan(data.y)\n",
    "        out = model(data)[mask]\n",
    "        y = data.y.to(torch.float)[mask]\n",
    "        loss = torch.nn.BCEWithLogitsLoss()(out, y)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "        #Â record beta and p values\n",
    "        if vals:\n",
    "            # display computational graph\n",
    "            # global g\n",
    "            #g = make_dot(out)\n",
    "            #Â \"a\"+9\n",
    "            values_batch = {}\n",
    "            values_batch[\"p\"]    = model.reader.p.detach().cpu().numpy()\n",
    "            values_batch[\"beta\"] = model.reader.beta.detach().cpu().numpy()\n",
    "            values.append(values_batch)\n",
    "            if False: # i==0:\n",
    "                print(\"records:\", i, \"value:\", values_batch)\n",
    "\n",
    "\n",
    "    return total_loss / len(train_loader.dataset), values\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    y_preds, y_trues = [], []\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        y_preds.append(model(data))\n",
    "        y_trues.append(data.y)\n",
    "\n",
    "    y_pred = torch.cat(y_preds, dim=0).cpu().numpy()\n",
    "    y_true = torch.cat(y_trues, dim=0).cpu().numpy()\n",
    "\n",
    "    rocauc_list = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        # AUC is only defined when there is at least one positive data.\n",
    "        if np.sum(y_true[:, i] == 1) > 0 and np.sum(y_true[:, i] == 0) > 0:\n",
    "            # ignore nan values\n",
    "            is_labeled = y_true[:, i] == y_true[:, i]\n",
    "            rocauc_list.append(\n",
    "                roc_auc_score(y_true[is_labeled, i], y_pred[is_labeled, i]))\n",
    "\n",
    "    return {\"rocauc\": sum(rocauc_list) / len(rocauc_list)}\n",
    "\n",
    "\n",
    "values     = []\n",
    "test_perfs = []\n",
    "for run in range(10):\n",
    "    print()\n",
    "    print(f'Run {run}:')\n",
    "    print()\n",
    "    model = Net(hidden_channels=args.hidden_channels,\n",
    "            out_channels=dataset.num_tasks, num_layers=args.num_layers,\n",
    "            dropout = args.dropout if run<10 else 0.6, # edited to increase dropout\n",
    "            inter_message_passing=not args.no_inter_message_passing).to(device)\n",
    "\n",
    "    model.reset_parameters()\n",
    "    optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    best_val_perf = test_perf = 0\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        loss, epoch_values = train(epoch, vals=True)\n",
    "        train_perf = test(train_loader)\n",
    "        val_perf = test(val_loader)\n",
    "\n",
    "        if val_perf[\"rocauc\"] > best_val_perf:\n",
    "            best_val_perf = val_perf[\"rocauc\"]\n",
    "            test_perf = test(test_loader)\n",
    "\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_perf[\"rocauc\"]:.4f}, Val: {val_perf[\"rocauc\"]:.4f}, '\n",
    "              f'Test: {test_perf[\"rocauc\"]:.4f}')\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Recorded values:\", epoch_values)\n",
    "\n",
    "    test_perfs.append(test_perf[\"rocauc\"])\n",
    "    values.append(epoch_values[-1])\n",
    "\n",
    "test_perf = torch.tensor(test_perfs)\n",
    "print('===========================')\n",
    "print(f'Final Test: {test_perf.mean():.4f} Â± {test_perf.std():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "p_epoch    = np.array([batch[\"p\"] for batch in epoch_values]).flatten()\n",
    "beta_epoch = np.array([batch[\"beta\"] for batch in epoch_values]).flatten() \n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.title(\"Evolution of parameters beta and p during training - Power Mean\")\n",
    "plt.plot(p_epoch, \"r-\", label=\"p\")\n",
    "plt.plot(beta_epoch, \"b-\", label=\"beta\")\n",
    "plt.ylim(0, 1.1*np.amax(np.maximum(p_epoch, beta_epoch)))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copia de analysis_molhiv_power.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
